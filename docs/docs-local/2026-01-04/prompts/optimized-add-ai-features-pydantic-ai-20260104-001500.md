# RAPO Optimization Report

## Metadata

- **Date**: 2026-01-04
- **Time**: 00:15:00
- **Project**: /home/leonai-do/Host-D-Drive/LeonAI_DO/dev/Agent-Skills
- **Branch**: feat/enhance-sitemap-content-mirroring
- **Base Prompt**: add the AI features to the @[skills-repository/sitemap_to_markdown] skill, to do that, we'll use pydantic AI instead of openai or anthropic...

---

## Analysis Summary

### Extracted Constraints

- **Framework**: Use `pydantic-ai` (v0.0.14+ expected).
- **Features**: Implement AI Summarization, Named Entity Extraction, and Semantic Chunking.
- **Existing Integration**: Stubs found in `InputModel` (lines 147-154) and CLI options (lines 1416-1420).
- **Dependency Management**: Add `pydantic-ai` and `logfire` (optional but recommended in docs) to `sitemap_to_markdown.py` script header.
- **Model Agnosticism**: Support multiple providers (OpenAI, Anthropic, Gemini) via Pydantic AI's native model support.

### Architectural Patterns

- **Async Orchestration**: The script follows an `asyncio` pattern with `httpx`. Pydantic AI's `Agent.run()` is fully compatible.
- **Phased Evolution**: Features are organized into 7 phases. AI Integration is Phase 6.
- **Checkpointing**: The skill maintains state; AI results should ideally be included in the manifest to avoid re-processing.

### Coding Conventions

- **Typing**: Strict Pydantic models for inputs and outputs.
- **Logging**: Use the internal `log(message: str)` function.
- **Error Handling**: Graceful fallback if AI fails (skip or log error).

### Known Pain Points

- **Stubbed Logic**: `summarize`, `extract_entities`, and `semantic_chunk` flags are defined but the logic in `process_url` is non-existent.
- **Token Limits**: `tiktoken` is imported but not yet leveraged to prevent context overflow or overcharging.

### Security & Privacy

- **API Keys**: Inherited from `InputModel`. Should be passed to Pydantic AI agents securely.
- **Content Masking**: PII handling (GDPR/CCPA) is mentioned in general RAPO rules; the prompt should ensure AI features respect privacy if possible.

---

## Optimized Prompt

### Character:

Expert Python AI Engineer specializing in Pydantic AI and Agentic Frameworks. You favor type-safe, model-agnostic implementations and production-grade reliability.

### Request:

Implement Phase 6 (AI Integration) of the `sitemap_to_markdown.py` skill using the `pydantic-ai` library. This involves:

1.  **Summarization Agent**: An agent that takes markdown content and returns a concise summary.
2.  **Entity Agent**: An agent that extracts named entities (People, Organizations, Locations, Dates) into a structured Pydantic model.
3.  **Semantic Chunking**: A logic block (or agent) that splits large documents into chunks based on semantic boundaries rather than simple character counts.
4.  **Integration**: Wire these features into the `process_url` flow, updating the file frontmatter and the `_manifest.json` correctly.

### Examples:

- **Summarization**: `summary: "This page explains the core principles of Pydantic AI agents."`
- **Entities**: `{ "people": ["Samuel Colvin"], "orgs": ["Pydantic"], "locations": ["London"] }`

### Adjustment:

- **Pydantic AI Workflow**: Define a global `Agent` instance (or instances) with specific `output_type` models.
- **Model Selection**: Map `inputs.ai_model` to Pydantic AI model strings (e.g., `openai:gpt-4o`).
- **Error Handling**: If `inputs.ai_api_key` is missing but AI flags are enabled, log a clear warning and skip AI processing.
- **Token Awareness**: Use `tiktoken` to check content length and truncate if necessary before sending to LLM.

### Type of Output:

- Modified `sitemap_to_markdown.py` with full Phase 6 implementation.
- Updated `SKILL.md` documenting AI capabilities.
- Unit tests in `tests/test_ai_features.py`.

### Extras:

Reference documentation in `skills-repository/sitemap_to_markdown/pydantic_ai_complete/` for implementation details. Specifically look at `output/index.md` for structured responses.

---

## Usage Instructions

1. Copy "Optimized Prompt" section.
2. Provide it to the next agent turn to implement the features.
3. Review the "Analysis Summary" to ensure constraints like `pydantic-ai` usage and phased implementation are followed.
4. Verify that `tiktoken` is used for content validation before LLM calls.

_Generated by RAPO on 2026-01-04 00:15:00_
